{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import jaccard_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The masks will need to be thresholded, as there may have been some interpolation when they were produced (show example here). Not all massk have 3 examples as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_IMAGES = 45\n",
    "\n",
    "images = [cv2.imread(f'./puzzle_data/images/image-{i}.jpg') for i in range(NUM_IMAGES)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks_0 = [cv2.threshold(cv2.imread(f'./puzzle_data/masks/mask-{i}-0.png', cv2.IMREAD_GRAYSCALE), 127, 255, cv2.THRESH_BINARY)[1] for i in range(NUM_IMAGES)]\n",
    "masks_1 = [cv2.threshold(cv2.imread(f'./puzzle_data/masks/mask-{i}-1.png', cv2.IMREAD_GRAYSCALE), 127, 255, cv2.THRESH_BINARY)[1] for i in range(NUM_IMAGES)]\n",
    "masks_2 = [cv2.threshold(cv2.imread(f'./puzzle_data/masks/mask-{i}-2.png', cv2.IMREAD_GRAYSCALE), 127, 255, cv2.THRESH_BINARY)[1] for i in range(NUM_IMAGES)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3840, 5120)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks_2[2].shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not all images are exactly the same size (see image 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 7 Mask 0 different size: (3844, 5120)\n",
      "Image 33 Mask 2 different size: (3848, 5120)\n",
      "Image 43 Mask 2 different size: (3844, 5120)\n"
     ]
    }
   ],
   "source": [
    "dim = (3840, 5120)\n",
    "for i in range(len(images)):\n",
    "\ttry:\n",
    "\t\tif masks_0[i].shape != dim: print(f'Image {i} Mask {0} different size: {masks_0[i].shape}')\n",
    "\t\tmasks_0[i] = cv2.resize(masks_0[i],dim)\n",
    "\texcept:\n",
    "\t\tpass\n",
    "\ttry:\n",
    "\t\tif masks_1[i].shape != dim: print(f'Image {i} Mask {1} different size: {masks_1[i].shape}')\n",
    "\t\tmasks_1[i] = cv2.resize(masks_1[i],dim)\n",
    "  \n",
    "\texcept:\n",
    "\t\tpass\n",
    "\ttry:\n",
    "\t\tif masks_2[i].shape != dim: print(f'Image {i} Mask {2} different size: {masks_2[i].shape}')\n",
    "\t\tmasks_2[i] = cv2.resize(masks_2[i],dim)\n",
    "  \n",
    "\texcept:\n",
    "\t\tpass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The masks are not all identical, see below. Some form of interpolation will need to be performed to reconcile the diferences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images are very large `(3840, 5120, 3)`, and so to speed up processing they will likely have to be scaled down. This may lead to some artifacts in the trianing data that may affect the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ValueError"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "multiclass-multioutput is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\joshu\\Dropbox\\CV4036A\\ComputerVisionLabs\\Lab5\\notebook.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/joshu/Dropbox/CV4036A/ComputerVisionLabs/Lab5/notebook.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(images)): \n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/joshu/Dropbox/CV4036A/ComputerVisionLabs/Lab5/notebook.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \tagr1 \u001b[39m=\u001b[39m jaccard_score(masks_0[i], masks_1[i], average\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmicro\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/joshu/Dropbox/CV4036A/ComputerVisionLabs/Lab5/notebook.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \t\u001b[39mtry\u001b[39;00m:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/joshu/Dropbox/CV4036A/ComputerVisionLabs/Lab5/notebook.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \t\tagr2 \u001b[39m=\u001b[39m jaccard_score(masks_0[i], masks_2[i], average\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmicro\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\joshu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:795\u001b[0m, in \u001b[0;36mjaccard_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m    667\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mjaccard_score\u001b[39m(\n\u001b[0;32m    668\u001b[0m     y_true,\n\u001b[0;32m    669\u001b[0m     y_pred,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    675\u001b[0m     zero_division\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    676\u001b[0m ):\n\u001b[0;32m    677\u001b[0m     \u001b[39m\"\"\"Jaccard similarity coefficient score.\u001b[39;00m\n\u001b[0;32m    678\u001b[0m \n\u001b[0;32m    679\u001b[0m \u001b[39m    The Jaccard index [1], or Jaccard similarity coefficient, defined as\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    793\u001b[0m \u001b[39m    array([1. , 0. , 0.33...])\u001b[39;00m\n\u001b[0;32m    794\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 795\u001b[0m     labels \u001b[39m=\u001b[39m _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n\u001b[0;32m    796\u001b[0m     samplewise \u001b[39m=\u001b[39m average \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msamples\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    797\u001b[0m     MCM \u001b[39m=\u001b[39m multilabel_confusion_matrix(\n\u001b[0;32m    798\u001b[0m         y_true,\n\u001b[0;32m    799\u001b[0m         y_pred,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    802\u001b[0m         samplewise\u001b[39m=\u001b[39msamplewise,\n\u001b[0;32m    803\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\joshu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1357\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1354\u001b[0m \u001b[39mif\u001b[39;00m average \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m average_options \u001b[39mand\u001b[39;00m average \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m   1355\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39maverage has to be one of \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(average_options))\n\u001b[1;32m-> 1357\u001b[0m y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m   1358\u001b[0m \u001b[39m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[39;00m\n\u001b[0;32m   1359\u001b[0m \u001b[39m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[39;00m\n\u001b[0;32m   1360\u001b[0m present_labels \u001b[39m=\u001b[39m unique_labels(y_true, y_pred)\u001b[39m.\u001b[39mtolist()\n",
      "File \u001b[1;32mc:\\Users\\joshu\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:104\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[39m# No metrics support \"multiclass-multioutput\" format\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[39mif\u001b[39;00m y_type \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmultilabel-indicator\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m--> 104\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m is not supported\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(y_type))\n\u001b[0;32m    106\u001b[0m \u001b[39mif\u001b[39;00m y_type \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m    107\u001b[0m     y_true \u001b[39m=\u001b[39m column_or_1d(y_true)\n",
      "\u001b[1;31mValueError\u001b[0m: multiclass-multioutput is not supported"
     ]
    }
   ],
   "source": [
    "for i in range(len(images)): \n",
    "\tagr1 = jaccard_score(masks_0[i], masks_1[i], average='micro')\n",
    "\t\n",
    "\ttry:\n",
    "\t\tagr2 = jaccard_score(masks_0[i], masks_2[i], average='micro')\n",
    "\t\tagr3 = jaccard_score(masks_1[i], masks_2[i], average='micro')\n",
    "\t\n",
    "\t\tprint(f'Image {i} average jaccard score: {(agr1 + agr2 + agr3)/3}')\n",
    "\texcept:\n",
    "\t\tprint(f'Image {i} average jaccard score: {agr1}')\n",
    "\t\t\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 0 average f1 score: 0.9960759572088698\n",
      "Image 1 average f1 score: 0.9790806093892567\n",
      "Image 2 average f1 score: 0.9857249226669142\n",
      "Image 4 average f1 score: 0.9953785781014673\n",
      "Image 5 average f1 score: 0.9941481553052585\n",
      "Image 6 average f1 score: 0.9809097442476135\n",
      "Image 8 average f1 score: 0.992939650292465\n",
      "Image 9 average f1 score: 0.9958599477824898\n",
      "Image 11 average f1 score: 0.9926426359033282\n",
      "Image 12 average f1 score: 0.9863616826092447\n",
      "Image 13 average f1 score: 0.9961424536443948\n",
      "Image 14 average f1 score: 0.9742287901515962\n",
      "Image 15 average f1 score: 0.9900088580617444\n",
      "Image 18 average f1 score: 0.9200283814166853\n",
      "Image 19 average f1 score: 0.9928785078940315\n",
      "Image 20 average f1 score: 0.9617981885727617\n",
      "Image 21 average f1 score: 0.9887464822903942\n",
      "Image 22 average f1 score: 0.9685814566630239\n",
      "Image 24 average f1 score: 0.984274235933244\n",
      "Image 25 average f1 score: 0.9912715147889245\n",
      "Image 26 average f1 score: 0.9934029059325741\n",
      "Image 28 average f1 score: 0.3345277409485117\n",
      "Image 30 average f1 score: 0.9939938999648614\n",
      "Image 32 average f1 score: 0.9948483888505478\n",
      "Image 34 average f1 score: 0.9932368664279766\n",
      "Image 35 average f1 score: 0.996967521021603\n",
      "Image 36 average f1 score: 0.9970046498769517\n",
      "Image 37 average f1 score: 0.9727687169438104\n",
      "Image 38 average f1 score: 0.33296533703109327\n",
      "Image 39 average f1 score: 0.9938779218556174\n",
      "Image 40 average f1 score: 0.9969382861653919\n",
      "Image 41 average f1 score: 0.9877754402447811\n",
      "Image 42 average f1 score: 0.9967841313913252\n",
      "Image 44 average f1 score: 0.99490776330645\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(images)): \n",
    "    try: \n",
    "        agr1 = f1_score(masks_0[i], masks_1[i], average='micro')\n",
    "        agr2 = f1_score(masks_0[i], masks_2[i], average='micro')\n",
    "        agr3 = f1_score(masks_1[i], masks_2[i], average='micro')\n",
    "        \n",
    "        print(f'Image {i} average f1 score: {(agr1 + agr2 + agr3)/3}')\n",
    "    except: \n",
    "        pass\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "01b0da322a7df2b881bf69dce4c75684d5ac75b853286a49a713693279c2c23c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
